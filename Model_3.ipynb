{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column='datetime'\n",
    "feature_columns = ['station_id', 'month', 'day', 'hour',\n",
    "       'lag_4h_percentage_docks_available',\n",
    "       'lag_3h_percentage_docks_available',\n",
    "       'lag_2h_percentage_docks_available',\n",
    "       'lag_1h_percentage_docks_available', 'capacity', 'lat', 'lon',\n",
    "       'altitude', 'post_code', 'year', 'day_of_week',\n",
    "       'lag_1h_is_interpolated', 'lag_2h_is_interpolated',\n",
    "       'lag_3h_is_interpolated', 'lag_4h_is_interpolated', 'FCB_Location',\n",
    "       'FCB_Score', 'wea_prep', 'wea_sun', 'wea_temp', 'wea_wind_sp',\n",
    "       'holiday', 'd_lag_1d_holiday',\n",
    "       'd_lead_1d_holiday', 't_lag_1h_FCB_Location', 't_lag_1h_FCB_Score', 't_lag_1h_wea_prep',\n",
    "       't_lag_1h_wea_sun', 't_lag_1h_wea_temp', 't_lag_1h_wea_wind_sp',\n",
    "       't_lag_2h_FCB_Location', 't_lag_2h_FCB_Score', 't_lag_2h_wea_prep',\n",
    "       't_lag_2h_wea_sun', 't_lag_2h_wea_temp', 't_lag_2h_wea_wind_sp',\n",
    "       't_lag_3h_FCB_Location', 't_lag_3h_FCB_Score', 't_lag_3h_wea_prep',\n",
    "       't_lag_3h_wea_sun', 't_lag_3h_wea_temp', 't_lag_3h_wea_wind_sp',\n",
    "       't_lag_4h_FCB_Location', 't_lag_4h_FCB_Score', 't_lag_4h_wea_prep',\n",
    "       't_lag_4h_wea_sun', 't_lag_4h_wea_temp', 't_lag_4h_wea_wind_sp',\n",
    "       't_lead_1h_FCB_Location', 't_lead_1h_FCB_Score', 't_lead_1h_wea_prep',\n",
    "       't_lead_1h_wea_sun', 't_lead_1h_wea_temp', 't_lead_1h_wea_wind_sp',\n",
    "       't_lead_2h_FCB_Location', 't_lead_2h_FCB_Score', 't_lead_2h_wea_prep',\n",
    "       't_lead_2h_wea_sun', 't_lead_2h_wea_temp', 't_lead_2h_wea_wind_sp',\n",
    "       't_lead_3h_FCB_Location', 't_lead_3h_FCB_Score', 't_lead_3h_wea_prep',\n",
    "       't_lead_3h_wea_sun', 't_lead_3h_wea_temp', 't_lead_3h_wea_wind_sp',\n",
    "       't_lead_4h_FCB_Location', 't_lead_4h_FCB_Score', 't_lead_4h_wea_prep',\n",
    "       't_lead_4h_wea_sun', 't_lead_4h_wea_temp', 't_lead_4h_wea_wind_sp']\n",
    "target_column = 'percentage_docks_available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all columns into one list\n",
    "selected_columns = feature_columns + [time_column] + [target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignas\\AppData\\Local\\Temp\\ipykernel_21744\\3046940161.py:2: DtypeWarning: Columns (17,19,21,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/Train_prepared_v3.csv') #.sample(frac=frac_load, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Load only the specified columns\n",
    "df = pd.read_csv('data/Train_prepared_v3.csv') #.sample(frac=frac_load, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14355983 entries, 0 to 14355982\n",
      "Data columns (total 81 columns):\n",
      " #   Column                             Dtype  \n",
      "---  ------                             -----  \n",
      " 0   Unnamed: 0                         int64  \n",
      " 1   station_id                         int64  \n",
      " 2   year                               int64  \n",
      " 3   month                              int64  \n",
      " 4   day                                int64  \n",
      " 5   hour                               int64  \n",
      " 6   date                               object \n",
      " 7   num_docks_available                float64\n",
      " 8   datetime                           object \n",
      " 9   capacity                           int64  \n",
      " 10  lat                                float64\n",
      " 11  lon                                float64\n",
      " 12  altitude                           float64\n",
      " 13  post_code                          float64\n",
      " 14  percentage_docks_available         float64\n",
      " 15  day_of_week                        int64  \n",
      " 16  lag_1h_percentage_docks_available  float64\n",
      " 17  lag_1h_is_interpolated             object \n",
      " 18  lag_2h_percentage_docks_available  float64\n",
      " 19  lag_2h_is_interpolated             object \n",
      " 20  lag_3h_percentage_docks_available  float64\n",
      " 21  lag_3h_is_interpolated             object \n",
      " 22  lag_4h_percentage_docks_available  float64\n",
      " 23  lag_4h_is_interpolated             object \n",
      " 24  FCB_Location                       object \n",
      " 25  FCB_Score                          object \n",
      " 26  wea_prep                           float64\n",
      " 27  wea_sun                            float64\n",
      " 28  wea_temp                           float64\n",
      " 29  wea_wind_sp                        float64\n",
      " 30  holiday                            float64\n",
      " 31  d_lag_1d_holiday                   float64\n",
      " 32  d_lead_1d_holiday                  float64\n",
      " 33  t_lag_1h_FCB_Location              object \n",
      " 34  t_lag_1h_FCB_Score                 object \n",
      " 35  t_lag_1h_wea_prep                  float64\n",
      " 36  t_lag_1h_wea_sun                   float64\n",
      " 37  t_lag_1h_wea_temp                  float64\n",
      " 38  t_lag_1h_wea_wind_sp               float64\n",
      " 39  t_lag_2h_FCB_Location              object \n",
      " 40  t_lag_2h_FCB_Score                 object \n",
      " 41  t_lag_2h_wea_prep                  float64\n",
      " 42  t_lag_2h_wea_sun                   float64\n",
      " 43  t_lag_2h_wea_temp                  float64\n",
      " 44  t_lag_2h_wea_wind_sp               float64\n",
      " 45  t_lag_3h_FCB_Location              object \n",
      " 46  t_lag_3h_FCB_Score                 object \n",
      " 47  t_lag_3h_wea_prep                  float64\n",
      " 48  t_lag_3h_wea_sun                   float64\n",
      " 49  t_lag_3h_wea_temp                  float64\n",
      " 50  t_lag_3h_wea_wind_sp               float64\n",
      " 51  t_lag_4h_FCB_Location              object \n",
      " 52  t_lag_4h_FCB_Score                 object \n",
      " 53  t_lag_4h_wea_prep                  float64\n",
      " 54  t_lag_4h_wea_sun                   float64\n",
      " 55  t_lag_4h_wea_temp                  float64\n",
      " 56  t_lag_4h_wea_wind_sp               float64\n",
      " 57  t_lead_1h_FCB_Location             object \n",
      " 58  t_lead_1h_FCB_Score                object \n",
      " 59  t_lead_1h_wea_prep                 float64\n",
      " 60  t_lead_1h_wea_sun                  float64\n",
      " 61  t_lead_1h_wea_temp                 float64\n",
      " 62  t_lead_1h_wea_wind_sp              float64\n",
      " 63  t_lead_2h_FCB_Location             object \n",
      " 64  t_lead_2h_FCB_Score                object \n",
      " 65  t_lead_2h_wea_prep                 float64\n",
      " 66  t_lead_2h_wea_sun                  float64\n",
      " 67  t_lead_2h_wea_temp                 float64\n",
      " 68  t_lead_2h_wea_wind_sp              float64\n",
      " 69  t_lead_3h_FCB_Location             object \n",
      " 70  t_lead_3h_FCB_Score                object \n",
      " 71  t_lead_3h_wea_prep                 float64\n",
      " 72  t_lead_3h_wea_sun                  float64\n",
      " 73  t_lead_3h_wea_temp                 float64\n",
      " 74  t_lead_3h_wea_wind_sp              float64\n",
      " 75  t_lead_4h_FCB_Location             object \n",
      " 76  t_lead_4h_FCB_Score                object \n",
      " 77  t_lead_4h_wea_prep                 float64\n",
      " 78  t_lead_4h_wea_sun                  float64\n",
      " 79  t_lead_4h_wea_temp                 float64\n",
      " 80  t_lead_4h_wea_wind_sp              float64\n",
      "dtypes: float64(49), int64(8), object(24)\n",
      "memory usage: 8.7+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert last_reported to datetime\n",
    "df[time_column] = pd.to_datetime(df[time_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_object_columns_to_boolean(df)\n",
    "\n",
    "\n",
    "convert_object_columns_to_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14355983 entries, 0 to 14355982\n",
      "Data columns (total 81 columns):\n",
      " #   Column                             Dtype         \n",
      "---  ------                             -----         \n",
      " 0   Unnamed: 0                         int64         \n",
      " 1   station_id                         int64         \n",
      " 2   year                               int64         \n",
      " 3   month                              int64         \n",
      " 4   day                                int64         \n",
      " 5   hour                               int64         \n",
      " 6   date                               category      \n",
      " 7   num_docks_available                float64       \n",
      " 8   datetime                           datetime64[ns]\n",
      " 9   capacity                           int64         \n",
      " 10  lat                                float64       \n",
      " 11  lon                                float64       \n",
      " 12  altitude                           float64       \n",
      " 13  post_code                          float64       \n",
      " 14  percentage_docks_available         float64       \n",
      " 15  day_of_week                        int64         \n",
      " 16  lag_1h_percentage_docks_available  float64       \n",
      " 17  lag_1h_is_interpolated             bool          \n",
      " 18  lag_2h_percentage_docks_available  float64       \n",
      " 19  lag_2h_is_interpolated             bool          \n",
      " 20  lag_3h_percentage_docks_available  float64       \n",
      " 21  lag_3h_is_interpolated             bool          \n",
      " 22  lag_4h_percentage_docks_available  float64       \n",
      " 23  lag_4h_is_interpolated             bool          \n",
      " 24  FCB_Location                       category      \n",
      " 25  FCB_Score                          category      \n",
      " 26  wea_prep                           float64       \n",
      " 27  wea_sun                            float64       \n",
      " 28  wea_temp                           float64       \n",
      " 29  wea_wind_sp                        float64       \n",
      " 30  holiday                            float64       \n",
      " 31  d_lag_1d_holiday                   float64       \n",
      " 32  d_lead_1d_holiday                  float64       \n",
      " 33  t_lag_1h_FCB_Location              category      \n",
      " 34  t_lag_1h_FCB_Score                 category      \n",
      " 35  t_lag_1h_wea_prep                  float64       \n",
      " 36  t_lag_1h_wea_sun                   float64       \n",
      " 37  t_lag_1h_wea_temp                  float64       \n",
      " 38  t_lag_1h_wea_wind_sp               float64       \n",
      " 39  t_lag_2h_FCB_Location              category      \n",
      " 40  t_lag_2h_FCB_Score                 category      \n",
      " 41  t_lag_2h_wea_prep                  float64       \n",
      " 42  t_lag_2h_wea_sun                   float64       \n",
      " 43  t_lag_2h_wea_temp                  float64       \n",
      " 44  t_lag_2h_wea_wind_sp               float64       \n",
      " 45  t_lag_3h_FCB_Location              category      \n",
      " 46  t_lag_3h_FCB_Score                 category      \n",
      " 47  t_lag_3h_wea_prep                  float64       \n",
      " 48  t_lag_3h_wea_sun                   float64       \n",
      " 49  t_lag_3h_wea_temp                  float64       \n",
      " 50  t_lag_3h_wea_wind_sp               float64       \n",
      " 51  t_lag_4h_FCB_Location              category      \n",
      " 52  t_lag_4h_FCB_Score                 category      \n",
      " 53  t_lag_4h_wea_prep                  float64       \n",
      " 54  t_lag_4h_wea_sun                   float64       \n",
      " 55  t_lag_4h_wea_temp                  float64       \n",
      " 56  t_lag_4h_wea_wind_sp               float64       \n",
      " 57  t_lead_1h_FCB_Location             category      \n",
      " 58  t_lead_1h_FCB_Score                category      \n",
      " 59  t_lead_1h_wea_prep                 float64       \n",
      " 60  t_lead_1h_wea_sun                  float64       \n",
      " 61  t_lead_1h_wea_temp                 float64       \n",
      " 62  t_lead_1h_wea_wind_sp              float64       \n",
      " 63  t_lead_2h_FCB_Location             category      \n",
      " 64  t_lead_2h_FCB_Score                category      \n",
      " 65  t_lead_2h_wea_prep                 float64       \n",
      " 66  t_lead_2h_wea_sun                  float64       \n",
      " 67  t_lead_2h_wea_temp                 float64       \n",
      " 68  t_lead_2h_wea_wind_sp              float64       \n",
      " 69  t_lead_3h_FCB_Location             category      \n",
      " 70  t_lead_3h_FCB_Score                category      \n",
      " 71  t_lead_3h_wea_prep                 float64       \n",
      " 72  t_lead_3h_wea_sun                  float64       \n",
      " 73  t_lead_3h_wea_temp                 float64       \n",
      " 74  t_lead_3h_wea_wind_sp              float64       \n",
      " 75  t_lead_4h_FCB_Location             category      \n",
      " 76  t_lead_4h_FCB_Score                category      \n",
      " 77  t_lead_4h_wea_prep                 float64       \n",
      " 78  t_lead_4h_wea_sun                  float64       \n",
      " 79  t_lead_4h_wea_temp                 float64       \n",
      " 80  t_lead_4h_wea_wind_sp              float64       \n",
      "dtypes: bool(4), category(19), datetime64[ns](1), float64(49), int64(8)\n",
      "memory usage: 6.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train, validation, and test splits based on time\n",
    "# Using 70% for training, 15% for validation, and 15% for testing\n",
    "train_end = df[time_column].quantile(0.7)\n",
    "\n",
    "train_data = df[df[time_column] <= train_end]\n",
    "val_data = df[df[time_column] > train_end]\n",
    "\n",
    "import gc\n",
    "\n",
    "del df  # Delete the DataFrame\n",
    "gc.collect()  # Force garbage collection\n",
    "\n",
    "# Split features and target\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "X_val = val_data[feature_columns]\n",
    "y_val = val_data[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imports for modeling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "# import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create LightGBM datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=True)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, free_raw_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "()'learning_rate': 0.017217810024463404, 'num_leaves': 592, 'max_depth': 35, 'min_data_in_leaf': 62, 'feature_fraction': 0.9939668052243837, 'bagging_fraction': 0.8406963017607484, 'bagging_freq': 5}. Best is trial 11 with value: 0.09624436082560552.\n",
    "Training until validation scores don't improve for 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# import optuna\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Define the objective function for Optuna to optimize\n",
    "# def objective(trial):\n",
    "#     # Define the hyperparameter search space using Optuna\n",
    "#     params = {\n",
    "#         'objective': 'regression',  # Task type (regression)\n",
    "#         'metric': 'rmse',  # Evaluation metric (Root Mean Squared Error)\n",
    "#         'verbosity': -1,  # Suppress LightGBM logs\n",
    "#         'boosting_type': 'gbdt',  # Gradient Boosting Decision Trees\n",
    "#         'feature_pre_filter': False,  # No pre-filtering of features\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),  # Learning rate (between 0.01 and 0.3)\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 1000),  # Maximum number of leaves per tree\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 100),  # Maximum tree depth\n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),  # Minimum number of data in a leaf\n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.8, 1.0),  # Fraction of features to use\n",
    "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.8, 1.0),  # Fraction of data to use for bagging\n",
    "#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),  # Frequency of bagging\n",
    "#     }\n",
    "\n",
    "#     # Train the model with the given hyperparameters\n",
    "#     model = lgb.train(\n",
    "#         params, \n",
    "#         train_data,  # Training dataset\n",
    "#         valid_sets=[val_data],  # Validation dataset\n",
    "#         num_boost_round=1000,  # Maximum training rounds\n",
    "#         callbacks=[\n",
    "#             lgb.early_stopping(stopping_rounds=100),  # Stop early if no improvement\n",
    "#             lgb.log_evaluation(0)  # Log evaluation results\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Make predictions on the validation set\n",
    "#     preds = model.predict(X_val)\n",
    "\n",
    "#     # Calculate RMSE (Root Mean Squared Error)\n",
    "#     rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "\n",
    "#     return rmse  # Return RMSE as the metric to minimize\n",
    "\n",
    "# # ========================\n",
    "# # 2. Run Hyperparameter Tuning\n",
    "# # ========================\n",
    "\n",
    "# # Create an Optuna study to minimize the RMSE\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# # Run optimization for 10 trials\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# # Retrieve the best hyperparameters from the study\n",
    "# best_params = study.best_trial.params\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# # ========================\n",
    "# # 3. Train Final Model with Best Hyperparameters\n",
    "# # ========================\n",
    "\n",
    "# # Use the best parameters found during tuning\n",
    "# final_params = {\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'rmse',\n",
    "#     'verbosity': -1,\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     **best_params  # Merge best hyperparameters into final parameters\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.035304947581187546, 'num_leaves': 403, 'max_depth': 43, 'min_data_in_leaf': 96, 'feature_fraction': 0.9000738036420937, 'bagging_fraction': 0.8577277335249167, 'bagging_freq': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's rmse: 0.111541\n",
      "[100]\tvalid_0's rmse: 0.101087\n",
      "[150]\tvalid_0's rmse: 0.0992409\n",
      "[200]\tvalid_0's rmse: 0.0982039\n",
      "[250]\tvalid_0's rmse: 0.0976251\n",
      "[300]\tvalid_0's rmse: 0.0972987\n",
      "[350]\tvalid_0's rmse: 0.0970501\n",
      "[400]\tvalid_0's rmse: 0.0968937\n",
      "[450]\tvalid_0's rmse: 0.0967823\n",
      "[500]\tvalid_0's rmse: 0.0966821\n",
      "[550]\tvalid_0's rmse: 0.0966066\n",
      "[600]\tvalid_0's rmse: 0.096498\n",
      "[650]\tvalid_0's rmse: 0.0964259\n",
      "[700]\tvalid_0's rmse: 0.0963773\n",
      "[750]\tvalid_0's rmse: 0.0963174\n",
      "[800]\tvalid_0's rmse: 0.096266\n",
      "[850]\tvalid_0's rmse: 0.0962068\n",
      "[900]\tvalid_0's rmse: 0.096173\n",
      "[950]\tvalid_0's rmse: 0.0961369\n",
      "[1000]\tvalid_0's rmse: 0.0961062\n",
      "[1050]\tvalid_0's rmse: 0.0960743\n",
      "[1100]\tvalid_0's rmse: 0.0960394\n",
      "[1150]\tvalid_0's rmse: 0.0960072\n",
      "[1200]\tvalid_0's rmse: 0.0959845\n",
      "[1250]\tvalid_0's rmse: 0.0959572\n",
      "[1300]\tvalid_0's rmse: 0.0959397\n",
      "[1350]\tvalid_0's rmse: 0.0959153\n",
      "[1400]\tvalid_0's rmse: 0.0958995\n",
      "[1450]\tvalid_0's rmse: 0.0958933\n",
      "[1500]\tvalid_0's rmse: 0.0958711\n",
      "[1550]\tvalid_0's rmse: 0.0958575\n",
      "[1600]\tvalid_0's rmse: 0.095832\n",
      "[1650]\tvalid_0's rmse: 0.0958106\n",
      "[1700]\tvalid_0's rmse: 0.0957873\n",
      "[1750]\tvalid_0's rmse: 0.0957708\n",
      "[1800]\tvalid_0's rmse: 0.0957571\n",
      "[1850]\tvalid_0's rmse: 0.0957474\n",
      "[1900]\tvalid_0's rmse: 0.0957356\n",
      "[1950]\tvalid_0's rmse: 0.0957259\n",
      "[2000]\tvalid_0's rmse: 0.0957144\n",
      "[2050]\tvalid_0's rmse: 0.0957095\n",
      "[2100]\tvalid_0's rmse: 0.0956932\n",
      "[2150]\tvalid_0's rmse: 0.0956851\n",
      "[2200]\tvalid_0's rmse: 0.0956722\n",
      "[2250]\tvalid_0's rmse: 0.0956601\n",
      "[2300]\tvalid_0's rmse: 0.0956567\n",
      "[2350]\tvalid_0's rmse: 0.0956612\n",
      "[2400]\tvalid_0's rmse: 0.0956554\n",
      "[2450]\tvalid_0's rmse: 0.0956514\n",
      "[2500]\tvalid_0's rmse: 0.0956473\n",
      "[2550]\tvalid_0's rmse: 0.0956463\n",
      "[2600]\tvalid_0's rmse: 0.0956446\n",
      "[2650]\tvalid_0's rmse: 0.0956436\n",
      "[2700]\tvalid_0's rmse: 0.095636\n",
      "[2750]\tvalid_0's rmse: 0.0956396\n",
      "[2800]\tvalid_0's rmse: 0.0956467\n",
      "Early stopping, best iteration is:\n",
      "[2702]\tvalid_0's rmse: 0.0956358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x2033caebd00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "model = lgb.train(\n",
    "    final_params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    num_boost_round=5000,  # Maximum training rounds\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),  # Early stopping\n",
    "        lgb.log_evaluation(50)  # Log evaluation results every 50 iterations\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save the trained model to a file\n",
    "model.save_model('lightgbm_free_docks_model_2.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "                              feature    importance\n",
      "7   lag_1h_percentage_docks_available  7.339136e+06\n",
      "6   lag_2h_percentage_docks_available  3.455162e+05\n",
      "3                                hour  5.644933e+04\n",
      "5   lag_3h_percentage_docks_available  5.243729e+04\n",
      "11                           altitude  5.032144e+04\n",
      "..                                ...           ...\n",
      "40              t_lag_3h_FCB_Location  1.665115e+01\n",
      "29                 t_lag_1h_FCB_Score  1.368881e+01\n",
      "41                 t_lag_3h_FCB_Score  9.228150e+00\n",
      "47                 t_lag_4h_FCB_Score  6.055074e+00\n",
      "46              t_lag_4h_FCB_Location  5.526932e+00\n",
      "\n",
      "[76 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "})\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.sort_values('importance', ascending=False).to_csv(f'model_3/feature_importance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x203382c2880>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final model on combined train and validation data using best iteration\n",
    "final_model = lgb.train(\n",
    "    final_params,\n",
    "    lgb.Dataset(pd.concat([X_train, X_val]), label=pd.concat([y_train, y_val])),\n",
    "    num_boost_round=3052 #model.best_iteration  # Use best iteration from previous validation\n",
    ")\n",
    "\n",
    "# Save the final model trained on combined data\n",
    "final_model.save_model('lightgbm_free_docks_model_final_2.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample= pd.read_csv('data\\Metadata_prepared_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_object_columns_to_boolean(sample)\n",
    "convert_object_columns_to_category(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns match: True\n"
     ]
    }
   ],
   "source": [
    "# Reorder the columns of prediction_data to match X_train's column order\n",
    "prediction_data = sample[X_train.columns]\n",
    "\n",
    "\n",
    "# Check if the columns of prediction_data match the columns of X_train\n",
    "columns_match = prediction_data.columns.tolist() == X_train.columns.tolist()\n",
    "\n",
    "# Print if the columns match\n",
    "print(\"Columns match:\", columns_match)\n",
    "\n",
    "# If the columns don't match, print the differences\n",
    "if not columns_match:\n",
    "    print(\"Columns in prediction_data that are not in X_train:\", set(prediction_data.columns) - set(X_train.columns))\n",
    "    print(\"Columns in X_train that are not in prediction_data:\", set(X_train.columns) - set(prediction_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.30474153 0.47701968 0.74546052 ... 0.51384785 0.51078024 0.52531953]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = final_model.predict(prediction_data)\n",
    "\n",
    "# Print or further process predictions\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final submission dataframe with explicit index\n",
    "final_submission = pd.DataFrame({\n",
    "    'index': range(len(predictions)),\n",
    "    'percentage_docks_available': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving final submission to: model_3/Sub_model_3_plain_3.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('model_3', exist_ok=True)\n",
    "\n",
    "# Get existing files matching pattern\n",
    "import glob\n",
    "import re\n",
    "\n",
    "existing_files = glob.glob('model_3/Sub_model_3_plain_*.csv')\n",
    "\n",
    "# Extract existing numbers and find max\n",
    "numbers = [int(re.search(r'plain_(\\d+)', f).group(1)) for f in existing_files if re.search(r'plain_(\\d+)', f)]\n",
    "next_num = max(numbers) + 1 if numbers else 1\n",
    "\n",
    "# Create final submission dataframe with explicit index and convert to numpy array first\n",
    "submission_data = np.column_stack((np.arange(len(predictions)), predictions))\n",
    "final_submission = pd.DataFrame(\n",
    "    submission_data, \n",
    "    columns=['index', 'percentage_docks_available']\n",
    ").astype({'index': int, 'percentage_docks_available': float})\n",
    "\n",
    "# Save to CSV\n",
    "output_file = f'model_3/Sub_model_3_plain_{next_num}.csv'\n",
    "print(f\"\\nSaving final submission to: {output_file}\")\n",
    "\n",
    "# Use numpy savetxt instead of pandas to_csv\n",
    "np.savetxt(\n",
    "    output_file,\n",
    "    submission_data,\n",
    "    delimiter=',',\n",
    "    header='index,percentage_docks_available',\n",
    "    comments='',\n",
    "    fmt=['%d', '%.6f']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "index                           int32\n",
      "percentage_docks_available    float64\n",
      "dtype: object\n",
      "Index(['index', 'percentage_docks_available'], dtype='object')\n",
      "RangeIndex(start=0, stop=401511, step=1)\n",
      "   index  percentage_docks_available\n",
      "0      0                    0.304742\n",
      "1      1                    0.477020\n",
      "2      2                    0.745461\n",
      "3      3                    0.787848\n",
      "4      4                    0.763783\n"
     ]
    }
   ],
   "source": [
    "print(type(final_submission))  # Confirm it's a DataFrame\n",
    "print(final_submission.dtypes)  # Check column data types\n",
    "print(final_submission.columns)  # See column names\n",
    "print(final_submission.index)  # Check index structure\n",
    "print(final_submission.head())  # Preview data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "-------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
